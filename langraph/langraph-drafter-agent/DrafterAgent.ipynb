{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pip install langchain langchain-openai \n",
    "# pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219c2a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "## Langchain\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "## Langgraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a38d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "document_content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2169097",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SequenceL\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba25d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def update(content: str) -> str:\n",
    "    \"\"\"Updates the document with the provided content\"\"\"\n",
    "    global document_content\n",
    "    document_content = content\n",
    "    return f\"Document has been updated. Content: \\n{document_content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfff377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def save(filename: str) -> str:\n",
    "    \"\"\" Save the current document to a text file and finish the process.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name for the text file.\n",
    "    \"\"\"\n",
    "\n",
    "    global document_content\n",
    "\n",
    "    if not filename.endswith('.txt'):\n",
    "        filename = f\"{filename}.txt\"\n",
    "\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(document_content)\n",
    "        print(f\"/n Document hast been saved to: {filename}\")\n",
    "        return f\"Docuemnt has been saved successfully to '{filename}'\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error saving document: '{str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b036e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [update, save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058aad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model = \"gpt-4o-mini\").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a4fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_agent(state: AgentState) -> AgentState:\n",
    "    system_prompt = SystemMessage(content=f\"\"\"\n",
    "    You are a Drafter, a helpful writing assistant. You helps the user to update and modify documents.\n",
    "    - If the user wants to update the content, use the 'update' tool\n",
    "    - If the user wants to save and finish, you need o use the 'save' tool. \n",
    "    - Make sure to always show the current document state after modifications.\n",
    "\n",
    "    The current document content is: {document_content}\n",
    "    \"\"\")\n",
    "\n",
    "    if not state[\"messages\"]:\n",
    "        user_input = \"I'm ready to help you update the document. What would you like to create?\"\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "        \n",
    "    else:\n",
    "        user_input = input(\"\\n What would you like to do wit the document? \\n\")\n",
    "        print(f\"\\n USER: {user_input}\")\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "        \n",
    "    all_messages = [system_prompt] + list(state[\"messages\"]) + [user_message]\n",
    "\n",
    "    response = model.invoke(all_messages)\n",
    "\n",
    "    print(f\"\\n AI: {response.content}\")\n",
    "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
    "        print(f\"USING TOOLS: {[tc['name'] for tc in response.tool_calls]}\")\n",
    "\n",
    "    return {\"messages\": list(state[\"messages\"]) + [user_message, response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b457241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determine if we should continue or end the conversation\"\"\"\n",
    "\n",
    "    messages = [\"messages\"]\n",
    "\n",
    "    if not messages:\n",
    "        return \"continue\"\n",
    "    \n",
    "    # This looks for the most rcent tool message...\n",
    "    for message in reversed(messages):\n",
    "        # ... and checks if this is a ToolMessage resulting from save\n",
    "        if (isinstance(message, ToolMessage) and\n",
    "            \"saved\" in message.content.lower() and\n",
    "            \"document\" in message.content.lower()):\n",
    "            return \"end\" # goes to the end edge\n",
    "        \n",
    "    return \"continue\"\n",
    "\n",
    "def print_messages(messages):\n",
    "    \"\"\"For printing messages in well format\"\"\"\n",
    "    if not messages:\n",
    "        return\n",
    "    \n",
    "    for message in messages[-3:]:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            print(f\"\\n TOOL RESULT: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===== DRAFTER AGENT =====\n",
      "\n",
      " AI: Please provide the content you would like to add or modify in the document, and I'll help you with the update.\n",
      "\n",
      " USER: \n",
      "\n",
      " AI: It looks like there was no content provided. Please let me know what updates you would like to make to the document!\n",
      "\n",
      " USER: hola como estas?\n",
      "\n",
      " AI: Parece que quieres actualizar el documento con un saludo. Voy a a√±adir \"hola como estas?\" al contenido del documento. \n",
      "\n",
      "Actualizando ahora...\n",
      "USING TOOLS: ['update']\n",
      "\n",
      " TOOL RESULT: Document has been updated. Content: \n",
      "hola como estas?\n"
     ]
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"agent\", our_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "graph.add_edge(\"agent\", \"tools\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"tools\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"agent\",\n",
    "        \"end\": END\n",
    "    },\n",
    ")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "def run_document_agent():\n",
    "    print(\"\\n ===== DRAFTER AGENT =====\")\n",
    "\n",
    "    state = {\"messages\": []}\n",
    "\n",
    "    for step in app.stream(state, stream_mode=\"values\"):\n",
    "        if \"messages\" in step:\n",
    "            print_messages(step[\"messages\"])\n",
    "        \n",
    "    print(\"\\n ====== DRAFTER FINISHED =======\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_document_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab2273b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===== DRAFTER =====\n",
      "\n",
      "ü§ñ AI: Great! Please let me know what content you would like to add or modify in your document, and I'll help you update it.\n",
      "\n",
      "üë§ USER: \n",
      "\n",
      "ü§ñ AI: It appears that there was no text or information provided. Could you please let me know what you would like to add or modify in your document?\n",
      "\n",
      "üë§ USER: I need to send a message to mark\n",
      "\n",
      "ü§ñ AI: What message would you like to include for Mark in the document? Please provide the content you'd like to add or modify.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 147\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m ===== DRAFTER FINISHED =====\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[43mrun_document_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 140\u001b[39m, in \u001b[36mrun_document_agent\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m ===== DRAFTER =====\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    138\u001b[39m state = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: []}\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Documents/projects/llm-agents/langraph/langraph-drafter-agent/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Documents/projects/llm-agents/langraph/langraph-drafter-agent/venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Documents/projects/llm-agents/langraph/langraph-drafter-agent/venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Documents/projects/llm-agents/langraph/langraph-drafter-agent/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Documents/projects/llm-agents/langraph/langraph-drafter-agent/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mour_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     68\u001b[39m     user_message = HumanMessage(content=user_input)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     user_input = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mWhat would you like to do with the document? \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müë§ USER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m     user_message = HumanMessage(content=user_input)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Documents/projects/llm-agents/langraph/langraph-drafter-agent/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Documents/projects/llm-agents/langraph/langraph-drafter-agent/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from dotenv import load_dotenv  \n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# This is the global variable to store document content\n",
    "document_content = \"\"\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "@tool\n",
    "def update(content: str) -> str:\n",
    "    \"\"\"Updates the document with the provided content.\"\"\"\n",
    "    global document_content\n",
    "    document_content = content\n",
    "    return f\"Document has been updated successfully! The current content is:\\n{document_content}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def save(filename: str) -> str:\n",
    "    \"\"\"Save the current document to a text file and finish the process.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name for the text file.\n",
    "    \"\"\"\n",
    "\n",
    "    global document_content\n",
    "\n",
    "    if not filename.endswith('.txt'):\n",
    "        filename = f\"{filename}.txt\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(document_content)\n",
    "        print(f\"\\nüíæ Document has been saved to: {filename}\")\n",
    "        return f\"Document has been saved successfully to '{filename}'.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error saving document: {str(e)}\"\n",
    "    \n",
    "\n",
    "tools = [update, save]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\").bind_tools(tools)\n",
    "\n",
    "def our_agent(state: AgentState) -> AgentState:\n",
    "    system_prompt = SystemMessage(content=f\"\"\"\n",
    "    You are Drafter, a helpful writing assistant. You are going to help the user update and modify documents.\n",
    "    \n",
    "    - If the user wants to update or modify content, use the 'update' tool with the complete updated content.\n",
    "    - If the user wants to save and finish, you need to use the 'save' tool.\n",
    "    - Make sure to always show the current document state after modifications.\n",
    "    \n",
    "    The current document content is:{document_content}\n",
    "    \"\"\")\n",
    "\n",
    "    if not state[\"messages\"]:\n",
    "        user_input = \"I'm ready to help you update a document. What would you like to create?\"\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "\n",
    "    else:\n",
    "        user_input = input(\"\\nWhat would you like to do with the document? \")\n",
    "        print(f\"\\nüë§ USER: {user_input}\")\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "\n",
    "    all_messages = [system_prompt] + list(state[\"messages\"]) + [user_message]\n",
    "\n",
    "    response = model.invoke(all_messages)\n",
    "\n",
    "    print(f\"\\nü§ñ AI: {response.content}\")\n",
    "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
    "        print(f\"üîß USING TOOLS: {[tc['name'] for tc in response.tool_calls]}\")\n",
    "\n",
    "    return {\"messages\": list(state[\"messages\"]) + [user_message, response]}\n",
    "\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determine if we should continue or end the conversation.\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    if not messages:\n",
    "        return \"continue\"\n",
    "    \n",
    "    # This looks for the most recent tool message....\n",
    "    for message in reversed(messages):\n",
    "        # ... and checks if this is a ToolMessage resulting from save\n",
    "        if (isinstance(message, ToolMessage) and \n",
    "            \"saved\" in message.content.lower() and\n",
    "            \"document\" in message.content.lower()):\n",
    "            return \"end\" # goes to the end edge which leads to the endpoint\n",
    "        \n",
    "    return \"continue\"\n",
    "\n",
    "def print_messages(messages):\n",
    "    \"\"\"Function I made to print the messages in a more readable format\"\"\"\n",
    "    if not messages:\n",
    "        return\n",
    "    \n",
    "    for message in messages[-3:]:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            print(f\"\\nüõ†Ô∏è TOOL RESULT: {message.content}\")\n",
    "\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"agent\", our_agent)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "graph.add_edge(\"agent\", \"tools\")\n",
    "\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"tools\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"agent\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "def run_document_agent():\n",
    "    print(\"\\n ===== DRAFTER =====\")\n",
    "    \n",
    "    state = {\"messages\": []}\n",
    "    \n",
    "    for step in app.stream(state, stream_mode=\"values\"):\n",
    "        if \"messages\" in step:\n",
    "            print_messages(step[\"messages\"])\n",
    "    \n",
    "    print(\"\\n ===== DRAFTER FINISHED =====\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_document_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3f4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f02ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
